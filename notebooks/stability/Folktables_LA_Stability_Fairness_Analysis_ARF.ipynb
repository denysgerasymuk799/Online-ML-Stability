{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from river import compose\n",
    "from river import preprocessing\n",
    "from river import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from source.config import *\n",
    "from source.utils.analysis_helper import load_groups_of_interest\n",
    "from source.stability.incremental_stability_analyzer import IncrementalStabilityAnalyzer\n",
    "from source.stability.stability_fairness_analyzer import StabilityFairnessAnalyzer\n",
    "from source.utils.incremental_model_utils import train_incremental_model\n",
    "from source.data_loaders.folktables_dataset_from_pd import FolktablesDatasetFromPandas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(15, 5)})\n",
    "dataset_name = 'folktables'\n",
    "state = 'LA'\n",
    "dataset_config = DATASETS_CONFIG[dataset_name]\n",
    "TARGET_COLUMN = dataset_config['target_column']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   AGEP  SCHL  MAR  RELP  DIS  ESP  CIT  MIG  MIL  ANC  NATIVITY  DEAR  DEYE  \\\n0    29    18    5    16    2    0    1    1    4    2         1     2     2   \n1    17    13    5    16    2    0    1    1    4    1         1     2     2   \n2    37    13    5    16    2    0    1    1    4    1         1     2     2   \n3    86    12    2    16    1    0    1    1    4    1         1     2     1   \n4    22    19    5    17    2    0    1    1    4    1         1     2     2   \n\n   DREM  SEX  RAC1P  ESR  \n0     2    1      1    0  \n1     2    1      2    0  \n2     2    1      1    0  \n3     2    2      2    0  \n4     2    2      1    0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGEP</th>\n      <th>SCHL</th>\n      <th>MAR</th>\n      <th>RELP</th>\n      <th>DIS</th>\n      <th>ESP</th>\n      <th>CIT</th>\n      <th>MIG</th>\n      <th>MIL</th>\n      <th>ANC</th>\n      <th>NATIVITY</th>\n      <th>DEAR</th>\n      <th>DEYE</th>\n      <th>DREM</th>\n      <th>SEX</th>\n      <th>RAC1P</th>\n      <th>ESR</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>29</td>\n      <td>18</td>\n      <td>5</td>\n      <td>16</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>17</td>\n      <td>13</td>\n      <td>5</td>\n      <td>16</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>13</td>\n      <td>5</td>\n      <td>16</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>86</td>\n      <td>12</td>\n      <td>2</td>\n      <td>16</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>22</td>\n      <td>19</td>\n      <td>5</td>\n      <td>17</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a data frame\n",
    "df = pd.read_csv(f\"../../datasets/folktables-{state}-2018.csv\", delimiter=',')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "(43588, 17)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['AGEP', 'SCHL', 'MAR', 'RELP', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC',\n       'NATIVITY', 'DEAR', 'DEYE', 'DREM', 'SEX', 'RAC1P', 'ESR'],\n      dtype='object')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "0    25363\n1    18225\nName: ESR, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ESR'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df shape:  (26154, 17)\n",
      "cv_df shape:  (8717, 17)\n",
      "test_df shape:  (8717, 17)\n"
     ]
    }
   ],
   "source": [
    "dataset_size = df.shape[0]\n",
    "test_size = int(TEST_FRACTION * dataset_size)\n",
    "validation_size = test_size\n",
    "\n",
    "train_cv_df, test_df = train_test_split(df, test_size=test_size, random_state=SEED)\n",
    "train_df, cv_df = train_test_split(train_cv_df, test_size=validation_size, random_state=SEED)\n",
    "print(\"train_df shape: \", train_df.shape)\n",
    "print(\"cv_df shape: \", cv_df.shape)\n",
    "print(\"test_df shape: \", test_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_dataset = FolktablesDatasetFromPandas(pd_dataset=train_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "['MAR',\n 'RELP',\n 'DIS',\n 'ESP',\n 'CIT',\n 'MIG',\n 'MIL',\n 'ANC',\n 'NATIVITY',\n 'DEAR',\n 'DEYE',\n 'DREM',\n 'SEX',\n 'RAC1P']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features = dataset_config['numerical_features']\n",
    "categorical_features = [feature for feature in df.columns if feature not in numerical_features + [TARGET_COLUMN]]\n",
    "\n",
    "categorical_features"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Apply data transformations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_transform_pipeline(categorical_features, numerical_features):\n",
    "    transform_pipeline = compose.Select(categorical_features[0])\n",
    "    for feature in categorical_features[1:]:\n",
    "        transform_pipeline += compose.Select(feature)\n",
    "    transform_pipeline |= preprocessing.OneHotEncoder()\n",
    "\n",
    "    for feature in numerical_features:\n",
    "        transform_pipeline += compose.Select(feature)\n",
    "    transform_pipeline |= preprocessing.MinMaxScaler()\n",
    "\n",
    "    return transform_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial features: {'AGEP': 93, 'SCHL': 19, 'MAR': '3', 'RELP': '0', 'DIS': '1', 'ESP': '0', 'CIT': '1', 'MIG': '1', 'MIL': '4', 'ANC': '4', 'NATIVITY': '1', 'DEAR': '2', 'DEYE': '1', 'DREM': '2', 'SEX': '2', 'RAC1P': '1'}\n",
      "\n",
      "Transformed features: {'SCHL': 0.0, 'AGEP': 0.0, 'RAC1P_1': 0.0, 'SEX_2': 0.0, 'DREM_2': 0.0, 'DEYE_1': 0.0, 'DEAR_2': 0.0, 'NATIVITY_1': 0.0, 'ANC_4': 0.0, 'MIL_4': 0.0, 'MIG_1': 0.0, 'CIT_1': 0.0, 'ESP_0': 0.0, 'DIS_1': 0.0, 'RELP_0': 0.0, 'MAR_3': 0.0}\n",
      "\n",
      "\n",
      "Initial features: {'AGEP': 58, 'SCHL': 23, 'MAR': '3', 'RELP': '0', 'DIS': '2', 'ESP': '0', 'CIT': '1', 'MIG': '1', 'MIL': '4', 'ANC': '2', 'NATIVITY': '1', 'DEAR': '2', 'DEYE': '2', 'DREM': '2', 'SEX': '1', 'RAC1P': '1'}\n",
      "\n",
      "Transformed features: {'SCHL': 1.0, 'AGEP': 0.0, 'RAC1P_1': 0.0, 'SEX_1': 0.0, 'SEX_2': 0.0, 'DREM_2': 0.0, 'DEYE_1': 0.0, 'DEYE_2': 0.0, 'DEAR_2': 0.0, 'NATIVITY_1': 0.0, 'ANC_4': 0.0, 'ANC_2': 0.0, 'MIL_4': 0.0, 'MIG_1': 0.0, 'CIT_1': 0.0, 'ESP_0': 0.0, 'DIS_1': 0.0, 'DIS_2': 0.0, 'RELP_0': 0.0, 'MAR_3': 0.0}\n",
      "\n",
      "\n",
      "Initial features: {'AGEP': 69, 'SCHL': 17, 'MAR': '3', 'RELP': '0', 'DIS': '1', 'ESP': '0', 'CIT': '1', 'MIG': '3', 'MIL': '4', 'ANC': '2', 'NATIVITY': '1', 'DEAR': '2', 'DEYE': '2', 'DREM': '2', 'SEX': '2', 'RAC1P': '1'}\n",
      "\n",
      "Transformed features: {'SCHL': 0.0, 'AGEP': 0.3142857142857143, 'RAC1P_1': 0.0, 'SEX_1': 0.0, 'SEX_2': 1.0, 'DREM_2': 0.0, 'DEYE_1': 0.0, 'DEYE_2': 0.0, 'DEAR_2': 0.0, 'NATIVITY_1': 0.0, 'ANC_4': 0.0, 'ANC_2': 0.0, 'MIL_4': 0.0, 'MIG_1': 0.0, 'MIG_3': 0.0, 'CIT_1': 0.0, 'ESP_0': 0.0, 'DIS_1': 1.0, 'DIS_2': 0.0, 'RELP_0': 0.0, 'MAR_3': 0.0}\n",
      "\n",
      "\n",
      "Initial features: {'AGEP': 28, 'SCHL': 22, 'MAR': '1', 'RELP': '0', 'DIS': '2', 'ESP': '0', 'CIT': '1', 'MIG': '3', 'MIL': '4', 'ANC': '4', 'NATIVITY': '1', 'DEAR': '2', 'DEYE': '2', 'DREM': '2', 'SEX': '2', 'RAC1P': '1'}\n",
      "\n",
      "Transformed features: {'SCHL': 0.8333333333333334, 'AGEP': 0.0, 'RAC1P_1': 0.0, 'SEX_1': 0.0, 'SEX_2': 1.0, 'DREM_2': 0.0, 'DEYE_1': 0.0, 'DEYE_2': 0.0, 'DEAR_2': 0.0, 'NATIVITY_1': 0.0, 'ANC_4': 1.0, 'ANC_2': 0.0, 'MIL_4': 0.0, 'MIG_1': 0.0, 'MIG_3': 0.0, 'CIT_1': 0.0, 'ESP_0': 0.0, 'DIS_1': 0.0, 'DIS_2': 1.0, 'RELP_0': 0.0, 'MAR_1': 0.0, 'MAR_3': 0.0}\n",
      "\n",
      "\n",
      "Initial features: {'AGEP': 35, 'SCHL': 16, 'MAR': '5', 'RELP': '0', 'DIS': '2', 'ESP': '0', 'CIT': '1', 'MIG': '1', 'MIL': '4', 'ANC': '1', 'NATIVITY': '1', 'DEAR': '2', 'DEYE': '2', 'DREM': '2', 'SEX': '2', 'RAC1P': '2'}\n",
      "\n",
      "Transformed features: {'SCHL': 0.0, 'AGEP': 0.1076923076923077, 'RAC1P_1': 0.0, 'RAC1P_2': 0.0, 'SEX_1': 0.0, 'SEX_2': 1.0, 'DREM_2': 0.0, 'DEYE_1': 0.0, 'DEYE_2': 0.0, 'DEAR_2': 0.0, 'NATIVITY_1': 0.0, 'ANC_1': 0.0, 'ANC_4': 0.0, 'ANC_2': 0.0, 'MIL_4': 0.0, 'MIG_1': 1.0, 'MIG_3': 0.0, 'CIT_1': 0.0, 'ESP_0': 0.0, 'DIS_1': 0.0, 'DIS_2': 1.0, 'RELP_0': 0.0, 'MAR_1': 0.0, 'MAR_3': 0.0, 'MAR_5': 0.0}\n",
      "\n",
      "\n",
      "Initial features: {'AGEP': 66, 'SCHL': 16, 'MAR': '1', 'RELP': '0', 'DIS': '2', 'ESP': '0', 'CIT': '1', 'MIG': '1', 'MIL': '4', 'ANC': '1', 'NATIVITY': '1', 'DEAR': '2', 'DEYE': '2', 'DREM': '2', 'SEX': '2', 'RAC1P': '1'}\n",
      "\n",
      "Transformed features: {'SCHL': 0.0, 'AGEP': 0.5846153846153846, 'RAC1P_1': 1.0, 'RAC1P_2': 0.0, 'SEX_1': 0.0, 'SEX_2': 1.0, 'DREM_2': 0.0, 'DEYE_1': 0.0, 'DEYE_2': 0.0, 'DEAR_2': 0.0, 'NATIVITY_1': 0.0, 'ANC_1': 0.0, 'ANC_4': 0.0, 'ANC_2': 0.0, 'MIL_4': 0.0, 'MIG_1': 1.0, 'MIG_3': 0.0, 'CIT_1': 0.0, 'ESP_0': 0.0, 'DIS_1': 0.0, 'DIS_2': 1.0, 'RELP_0': 0.0, 'MAR_1': 1.0, 'MAR_3': 0.0, 'MAR_5': 0.0}\n",
      "\n",
      "\n",
      "Initial features: {'AGEP': 41, 'SCHL': 18, 'MAR': '1', 'RELP': '0', 'DIS': '2', 'ESP': '0', 'CIT': '1', 'MIG': '1', 'MIL': '4', 'ANC': '2', 'NATIVITY': '1', 'DEAR': '2', 'DEYE': '2', 'DREM': '2', 'SEX': '1', 'RAC1P': '1'}\n",
      "\n",
      "Transformed features: {'SCHL': 0.2857142857142857, 'AGEP': 0.2, 'RAC1P_1': 1.0, 'RAC1P_2': 0.0, 'SEX_1': 1.0, 'SEX_2': 0.0, 'DREM_2': 0.0, 'DEYE_1': 0.0, 'DEYE_2': 0.0, 'DEAR_2': 0.0, 'NATIVITY_1': 0.0, 'ANC_1': 0.0, 'ANC_4': 0.0, 'ANC_2': 1.0, 'MIL_4': 0.0, 'MIG_1': 1.0, 'MIG_3': 0.0, 'CIT_1': 0.0, 'ESP_0': 0.0, 'DIS_1': 0.0, 'DIS_2': 1.0, 'RELP_0': 0.0, 'MAR_1': 1.0, 'MAR_3': 0.0, 'MAR_5': 0.0}\n",
      "\n",
      "\n",
      "Initial features: {'AGEP': 15, 'SCHL': 11, 'MAR': '5', 'RELP': '2', 'DIS': '1', 'ESP': '2', 'CIT': '1', 'MIG': '1', 'MIL': '0', 'ANC': '3', 'NATIVITY': '1', 'DEAR': '2', 'DEYE': '2', 'DREM': '1', 'SEX': '1', 'RAC1P': '1'}\n",
      "\n",
      "Transformed features: {'SCHL': 0.0, 'AGEP': 0.0, 'RAC1P_1': 1.0, 'RAC1P_2': 0.0, 'SEX_1': 1.0, 'SEX_2': 0.0, 'DREM_1': 0.0, 'DREM_2': 0.0, 'DEYE_1': 0.0, 'DEYE_2': 0.0, 'DEAR_2': 0.0, 'NATIVITY_1': 0.0, 'ANC_1': 0.0, 'ANC_4': 0.0, 'ANC_3': 0.0, 'ANC_2': 0.0, 'MIL_0': 0.0, 'MIL_4': 0.0, 'MIG_1': 1.0, 'MIG_3': 0.0, 'CIT_1': 0.0, 'ESP_0': 0.0, 'ESP_2': 0.0, 'DIS_1': 1.0, 'DIS_2': 0.0, 'RELP_0': 0.0, 'RELP_2': 0.0, 'MAR_1': 0.0, 'MAR_3': 0.0, 'MAR_5': 1.0}\n",
      "\n",
      "\n",
      "Initial features: {'AGEP': 51, 'SCHL': 16, 'MAR': '1', 'RELP': '1', 'DIS': '2', 'ESP': '0', 'CIT': '1', 'MIG': '1', 'MIL': '4', 'ANC': '1', 'NATIVITY': '1', 'DEAR': '2', 'DEYE': '2', 'DREM': '2', 'SEX': '2', 'RAC1P': '2'}\n",
      "\n",
      "Transformed features: {'SCHL': 0.4166666666666667, 'AGEP': 0.46153846153846156, 'RAC1P_1': 0.0, 'RAC1P_2': 1.0, 'SEX_1': 0.0, 'SEX_2': 1.0, 'DREM_1': 0.0, 'DREM_2': 1.0, 'DEYE_1': 0.0, 'DEYE_2': 0.0, 'DEAR_2': 0.0, 'NATIVITY_1': 0.0, 'ANC_1': 1.0, 'ANC_4': 0.0, 'ANC_3': 0.0, 'ANC_2': 0.0, 'MIL_0': 0.0, 'MIL_4': 1.0, 'MIG_1': 1.0, 'MIG_3': 0.0, 'CIT_1': 0.0, 'ESP_0': 1.0, 'ESP_2': 0.0, 'DIS_1': 0.0, 'DIS_2': 1.0, 'RELP_0': 0.0, 'RELP_1': 0.0, 'RELP_2': 0.0, 'MAR_1': 1.0, 'MAR_3': 0.0, 'MAR_5': 0.0}\n",
      "\n",
      "\n",
      "Initial features: {'AGEP': 73, 'SCHL': 15, 'MAR': '1', 'RELP': '1', 'DIS': '1', 'ESP': '0', 'CIT': '1', 'MIG': '1', 'MIL': '4', 'ANC': '1', 'NATIVITY': '1', 'DEAR': '2', 'DEYE': '1', 'DREM': '1', 'SEX': '2', 'RAC1P': '1'}\n",
      "\n",
      "Transformed features: {'SCHL': 0.3333333333333333, 'AGEP': 0.7435897435897436, 'RAC1P_1': 1.0, 'RAC1P_2': 0.0, 'SEX_1': 0.0, 'SEX_2': 1.0, 'DREM_1': 1.0, 'DREM_2': 0.0, 'DEYE_1': 1.0, 'DEYE_2': 0.0, 'DEAR_2': 0.0, 'NATIVITY_1': 0.0, 'ANC_1': 1.0, 'ANC_4': 0.0, 'ANC_3': 0.0, 'ANC_2': 0.0, 'MIL_0': 0.0, 'MIL_4': 1.0, 'MIG_1': 1.0, 'MIG_3': 0.0, 'CIT_1': 0.0, 'ESP_0': 1.0, 'ESP_2': 0.0, 'DIS_1': 1.0, 'DIS_2': 0.0, 'RELP_0': 0.0, 'RELP_1': 0.0, 'RELP_2': 0.0, 'MAR_1': 1.0, 'MAR_3': 0.0, 'MAR_5': 0.0}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform_pipeline = get_transform_pipeline(categorical_features, numerical_features)\n",
    "\n",
    "for idx, (x, y) in enumerate(train_dataset):\n",
    "    print(f'Initial features: {x}\\n')\n",
    "    x = transform_pipeline.transform_one(x)\n",
    "    print(f'Transformed features: {x}\\n\\n')\n",
    "    if idx + 1 == 10:\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Analyze stability of Adaptive Random Forest classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_base_model():\n",
    "    return ensemble.AdaptiveRandomForestClassifier(n_models=10, seed=SEED, split_criterion='gini'), 'Adaptive Random Forest'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:31:06 incremental_model_utils.py INFO    : Iteration 1000/26154 -- Accuracy: 75.08%; WeightedF1: 74.89%\n",
      "2022-11-29 16:31:08 incremental_model_utils.py INFO    : Iteration 2000/26154 -- Accuracy: 77.24%; WeightedF1: 77.23%\n",
      "2022-11-29 16:31:10 incremental_model_utils.py INFO    : Iteration 3000/26154 -- Accuracy: 78.03%; WeightedF1: 78.10%\n",
      "2022-11-29 16:31:12 incremental_model_utils.py INFO    : Iteration 4000/26154 -- Accuracy: 78.72%; WeightedF1: 78.81%\n",
      "2022-11-29 16:31:14 incremental_model_utils.py INFO    : Iteration 5000/26154 -- Accuracy: 79.40%; WeightedF1: 79.47%\n",
      "2022-11-29 16:31:16 incremental_model_utils.py INFO    : Iteration 6000/26154 -- Accuracy: 79.35%; WeightedF1: 79.43%\n",
      "2022-11-29 16:31:17 incremental_model_utils.py INFO    : Iteration 7000/26154 -- Accuracy: 79.54%; WeightedF1: 79.63%\n",
      "2022-11-29 16:31:19 incremental_model_utils.py INFO    : Iteration 8000/26154 -- Accuracy: 79.70%; WeightedF1: 79.78%\n",
      "2022-11-29 16:31:21 incremental_model_utils.py INFO    : Iteration 9000/26154 -- Accuracy: 79.76%; WeightedF1: 79.85%\n",
      "2022-11-29 16:31:23 incremental_model_utils.py INFO    : Iteration 10000/26154 -- Accuracy: 79.62%; WeightedF1: 79.69%\n",
      "2022-11-29 16:31:25 incremental_model_utils.py INFO    : Iteration 11000/26154 -- Accuracy: 79.54%; WeightedF1: 79.61%\n",
      "2022-11-29 16:31:26 incremental_model_utils.py INFO    : Iteration 12000/26154 -- Accuracy: 79.61%; WeightedF1: 79.68%\n",
      "2022-11-29 16:31:28 incremental_model_utils.py INFO    : Iteration 13000/26154 -- Accuracy: 79.45%; WeightedF1: 79.52%\n",
      "2022-11-29 16:31:30 incremental_model_utils.py INFO    : Iteration 14000/26154 -- Accuracy: 79.62%; WeightedF1: 79.69%\n",
      "2022-11-29 16:31:32 incremental_model_utils.py INFO    : Iteration 15000/26154 -- Accuracy: 79.64%; WeightedF1: 79.71%\n",
      "2022-11-29 16:31:34 incremental_model_utils.py INFO    : Iteration 16000/26154 -- Accuracy: 79.71%; WeightedF1: 79.78%\n",
      "2022-11-29 16:31:36 incremental_model_utils.py INFO    : Iteration 17000/26154 -- Accuracy: 79.82%; WeightedF1: 79.88%\n",
      "2022-11-29 16:31:38 incremental_model_utils.py INFO    : Iteration 18000/26154 -- Accuracy: 79.95%; WeightedF1: 80.02%\n",
      "2022-11-29 16:31:40 incremental_model_utils.py INFO    : Iteration 19000/26154 -- Accuracy: 80.01%; WeightedF1: 80.08%\n",
      "2022-11-29 16:31:42 incremental_model_utils.py INFO    : Iteration 20000/26154 -- Accuracy: 80.11%; WeightedF1: 80.18%\n",
      "2022-11-29 16:31:44 incremental_model_utils.py INFO    : Iteration 21000/26154 -- Accuracy: 80.08%; WeightedF1: 80.15%\n",
      "2022-11-29 16:31:46 incremental_model_utils.py INFO    : Iteration 22000/26154 -- Accuracy: 80.04%; WeightedF1: 80.11%\n",
      "2022-11-29 16:31:49 incremental_model_utils.py INFO    : Iteration 23000/26154 -- Accuracy: 80.15%; WeightedF1: 80.22%\n",
      "2022-11-29 16:31:51 incremental_model_utils.py INFO    : Iteration 24000/26154 -- Accuracy: 80.17%; WeightedF1: 80.25%\n",
      "2022-11-29 16:31:53 incremental_model_utils.py INFO    : Iteration 25000/26154 -- Accuracy: 80.28%; WeightedF1: 80.36%\n",
      "2022-11-29 16:31:56 incremental_model_utils.py INFO    : Iteration 26000/26154 -- Accuracy: 80.24%; WeightedF1: 80.32%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Metrics after incremental model training:\n",
      "Accuracy: 80.25%\n",
      "WeightedF1: 80.33%\n"
     ]
    }
   ],
   "source": [
    "base_model, base_model_name = get_base_model()\n",
    "\n",
    "# Conduct model training\n",
    "base_model = train_incremental_model(base_model, train_dataset, train_df.shape[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "X_test_df = test_df.drop([TARGET_COLUMN], axis=1)\n",
    "test_groups = load_groups_of_interest(group_info=TEST_GROUPS_CONFIG['folktables'], X_test_df=X_test_df)\n",
    "stability_analyzer = IncrementalStabilityAnalyzer(base_model,\n",
    "                                                  base_model_name=base_model_name,\n",
    "                                                  train_pd_dataset=cv_df,\n",
    "                                                  test_pd_dataset=test_df,\n",
    "                                                  test_y_true=test_df[TARGET_COLUMN],\n",
    "                                                  dataset_reader=FolktablesDatasetFromPandas,\n",
    "                                                  dataset_name=dataset_name + '_LA',\n",
    "                                                  n_estimators=200)\n",
    "\n",
    "stability_fairness_analyzer = StabilityFairnessAnalyzer(stability_analyzer, test_groups)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 16:38:17 base_stability_analyzer.py INFO    : Start testing of classifier 1 / 200\n",
      "2022-11-29 16:38:28 base_stability_analyzer.py INFO    : Classifier 1 / 200 was tested\n",
      "2022-11-29 16:38:28 base_stability_analyzer.py INFO    : Start testing of classifier 2 / 200\n",
      "2022-11-29 16:38:39 base_stability_analyzer.py INFO    : Classifier 2 / 200 was tested\n",
      "2022-11-29 16:38:39 base_stability_analyzer.py INFO    : Start testing of classifier 3 / 200\n",
      "2022-11-29 16:38:49 base_stability_analyzer.py INFO    : Classifier 3 / 200 was tested\n",
      "2022-11-29 16:38:49 base_stability_analyzer.py INFO    : Start testing of classifier 4 / 200\n",
      "2022-11-29 16:39:00 base_stability_analyzer.py INFO    : Classifier 4 / 200 was tested\n",
      "2022-11-29 16:39:00 base_stability_analyzer.py INFO    : Start testing of classifier 5 / 200\n",
      "2022-11-29 16:39:11 base_stability_analyzer.py INFO    : Classifier 5 / 200 was tested\n",
      "2022-11-29 16:39:11 base_stability_analyzer.py INFO    : Start testing of classifier 6 / 200\n",
      "2022-11-29 16:39:21 base_stability_analyzer.py INFO    : Classifier 6 / 200 was tested\n",
      "2022-11-29 16:39:21 base_stability_analyzer.py INFO    : Start testing of classifier 7 / 200\n",
      "2022-11-29 16:39:32 base_stability_analyzer.py INFO    : Classifier 7 / 200 was tested\n",
      "2022-11-29 16:39:32 base_stability_analyzer.py INFO    : Start testing of classifier 8 / 200\n",
      "2022-11-29 16:39:43 base_stability_analyzer.py INFO    : Classifier 8 / 200 was tested\n",
      "2022-11-29 16:39:43 base_stability_analyzer.py INFO    : Start testing of classifier 9 / 200\n",
      "2022-11-29 16:39:54 base_stability_analyzer.py INFO    : Classifier 9 / 200 was tested\n",
      "2022-11-29 16:39:54 base_stability_analyzer.py INFO    : Start testing of classifier 10 / 200\n",
      "2022-11-29 16:40:05 base_stability_analyzer.py INFO    : Classifier 10 / 200 was tested\n",
      "2022-11-29 16:40:05 base_stability_analyzer.py INFO    : Start testing of classifier 11 / 200\n",
      "2022-11-29 16:40:16 base_stability_analyzer.py INFO    : Classifier 11 / 200 was tested\n",
      "2022-11-29 16:40:16 base_stability_analyzer.py INFO    : Start testing of classifier 12 / 200\n",
      "2022-11-29 16:40:27 base_stability_analyzer.py INFO    : Classifier 12 / 200 was tested\n",
      "2022-11-29 16:40:27 base_stability_analyzer.py INFO    : Start testing of classifier 13 / 200\n",
      "2022-11-29 16:40:37 base_stability_analyzer.py INFO    : Classifier 13 / 200 was tested\n",
      "2022-11-29 16:40:37 base_stability_analyzer.py INFO    : Start testing of classifier 14 / 200\n",
      "2022-11-29 16:40:48 base_stability_analyzer.py INFO    : Classifier 14 / 200 was tested\n",
      "2022-11-29 16:40:48 base_stability_analyzer.py INFO    : Start testing of classifier 15 / 200\n",
      "2022-11-29 16:40:59 base_stability_analyzer.py INFO    : Classifier 15 / 200 was tested\n",
      "2022-11-29 16:40:59 base_stability_analyzer.py INFO    : Start testing of classifier 16 / 200\n",
      "2022-11-29 16:41:10 base_stability_analyzer.py INFO    : Classifier 16 / 200 was tested\n",
      "2022-11-29 16:41:10 base_stability_analyzer.py INFO    : Start testing of classifier 17 / 200\n",
      "2022-11-29 16:41:21 base_stability_analyzer.py INFO    : Classifier 17 / 200 was tested\n",
      "2022-11-29 16:41:21 base_stability_analyzer.py INFO    : Start testing of classifier 18 / 200\n",
      "2022-11-29 16:41:31 base_stability_analyzer.py INFO    : Classifier 18 / 200 was tested\n",
      "2022-11-29 16:41:31 base_stability_analyzer.py INFO    : Start testing of classifier 19 / 200\n",
      "2022-11-29 16:41:42 base_stability_analyzer.py INFO    : Classifier 19 / 200 was tested\n",
      "2022-11-29 16:41:42 base_stability_analyzer.py INFO    : Start testing of classifier 20 / 200\n",
      "2022-11-29 16:41:54 base_stability_analyzer.py INFO    : Classifier 20 / 200 was tested\n",
      "2022-11-29 16:41:54 base_stability_analyzer.py INFO    : Start testing of classifier 21 / 200\n",
      "2022-11-29 16:42:06 base_stability_analyzer.py INFO    : Classifier 21 / 200 was tested\n",
      "2022-11-29 16:42:06 base_stability_analyzer.py INFO    : Start testing of classifier 22 / 200\n",
      "2022-11-29 16:42:16 base_stability_analyzer.py INFO    : Classifier 22 / 200 was tested\n",
      "2022-11-29 16:42:16 base_stability_analyzer.py INFO    : Start testing of classifier 23 / 200\n",
      "2022-11-29 16:42:27 base_stability_analyzer.py INFO    : Classifier 23 / 200 was tested\n",
      "2022-11-29 16:42:27 base_stability_analyzer.py INFO    : Start testing of classifier 24 / 200\n",
      "2022-11-29 16:42:38 base_stability_analyzer.py INFO    : Classifier 24 / 200 was tested\n",
      "2022-11-29 16:42:38 base_stability_analyzer.py INFO    : Start testing of classifier 25 / 200\n",
      "2022-11-29 16:42:49 base_stability_analyzer.py INFO    : Classifier 25 / 200 was tested\n",
      "2022-11-29 16:42:49 base_stability_analyzer.py INFO    : Start testing of classifier 26 / 200\n",
      "2022-11-29 16:43:01 base_stability_analyzer.py INFO    : Classifier 26 / 200 was tested\n",
      "2022-11-29 16:43:01 base_stability_analyzer.py INFO    : Start testing of classifier 27 / 200\n",
      "2022-11-29 16:43:12 base_stability_analyzer.py INFO    : Classifier 27 / 200 was tested\n",
      "2022-11-29 16:43:12 base_stability_analyzer.py INFO    : Start testing of classifier 28 / 200\n",
      "2022-11-29 16:43:22 base_stability_analyzer.py INFO    : Classifier 28 / 200 was tested\n",
      "2022-11-29 16:43:22 base_stability_analyzer.py INFO    : Start testing of classifier 29 / 200\n",
      "2022-11-29 16:43:32 base_stability_analyzer.py INFO    : Classifier 29 / 200 was tested\n",
      "2022-11-29 16:43:32 base_stability_analyzer.py INFO    : Start testing of classifier 30 / 200\n",
      "2022-11-29 16:43:42 base_stability_analyzer.py INFO    : Classifier 30 / 200 was tested\n",
      "2022-11-29 16:43:42 base_stability_analyzer.py INFO    : Start testing of classifier 31 / 200\n",
      "2022-11-29 16:43:52 base_stability_analyzer.py INFO    : Classifier 31 / 200 was tested\n",
      "2022-11-29 16:43:52 base_stability_analyzer.py INFO    : Start testing of classifier 32 / 200\n",
      "2022-11-29 16:44:02 base_stability_analyzer.py INFO    : Classifier 32 / 200 was tested\n",
      "2022-11-29 16:44:02 base_stability_analyzer.py INFO    : Start testing of classifier 33 / 200\n",
      "2022-11-29 16:44:12 base_stability_analyzer.py INFO    : Classifier 33 / 200 was tested\n",
      "2022-11-29 16:44:12 base_stability_analyzer.py INFO    : Start testing of classifier 34 / 200\n",
      "2022-11-29 16:44:22 base_stability_analyzer.py INFO    : Classifier 34 / 200 was tested\n",
      "2022-11-29 16:44:22 base_stability_analyzer.py INFO    : Start testing of classifier 35 / 200\n",
      "2022-11-29 16:44:32 base_stability_analyzer.py INFO    : Classifier 35 / 200 was tested\n",
      "2022-11-29 16:44:32 base_stability_analyzer.py INFO    : Start testing of classifier 36 / 200\n",
      "2022-11-29 16:44:42 base_stability_analyzer.py INFO    : Classifier 36 / 200 was tested\n",
      "2022-11-29 16:44:42 base_stability_analyzer.py INFO    : Start testing of classifier 37 / 200\n",
      "2022-11-29 16:44:52 base_stability_analyzer.py INFO    : Classifier 37 / 200 was tested\n",
      "2022-11-29 16:44:52 base_stability_analyzer.py INFO    : Start testing of classifier 38 / 200\n",
      "2022-11-29 16:45:02 base_stability_analyzer.py INFO    : Classifier 38 / 200 was tested\n",
      "2022-11-29 16:45:02 base_stability_analyzer.py INFO    : Start testing of classifier 39 / 200\n",
      "2022-11-29 16:45:12 base_stability_analyzer.py INFO    : Classifier 39 / 200 was tested\n",
      "2022-11-29 16:45:12 base_stability_analyzer.py INFO    : Start testing of classifier 40 / 200\n",
      "2022-11-29 16:45:22 base_stability_analyzer.py INFO    : Classifier 40 / 200 was tested\n",
      "2022-11-29 16:45:22 base_stability_analyzer.py INFO    : Start testing of classifier 41 / 200\n",
      "2022-11-29 16:45:32 base_stability_analyzer.py INFO    : Classifier 41 / 200 was tested\n",
      "2022-11-29 16:45:32 base_stability_analyzer.py INFO    : Start testing of classifier 42 / 200\n",
      "2022-11-29 16:45:42 base_stability_analyzer.py INFO    : Classifier 42 / 200 was tested\n",
      "2022-11-29 16:45:42 base_stability_analyzer.py INFO    : Start testing of classifier 43 / 200\n",
      "2022-11-29 16:45:52 base_stability_analyzer.py INFO    : Classifier 43 / 200 was tested\n",
      "2022-11-29 16:45:52 base_stability_analyzer.py INFO    : Start testing of classifier 44 / 200\n",
      "2022-11-29 16:46:02 base_stability_analyzer.py INFO    : Classifier 44 / 200 was tested\n",
      "2022-11-29 16:46:02 base_stability_analyzer.py INFO    : Start testing of classifier 45 / 200\n",
      "2022-11-29 16:46:12 base_stability_analyzer.py INFO    : Classifier 45 / 200 was tested\n",
      "2022-11-29 16:46:12 base_stability_analyzer.py INFO    : Start testing of classifier 46 / 200\n",
      "2022-11-29 16:46:22 base_stability_analyzer.py INFO    : Classifier 46 / 200 was tested\n",
      "2022-11-29 16:46:22 base_stability_analyzer.py INFO    : Start testing of classifier 47 / 200\n",
      "2022-11-29 16:46:32 base_stability_analyzer.py INFO    : Classifier 47 / 200 was tested\n",
      "2022-11-29 16:46:32 base_stability_analyzer.py INFO    : Start testing of classifier 48 / 200\n",
      "2022-11-29 16:46:42 base_stability_analyzer.py INFO    : Classifier 48 / 200 was tested\n",
      "2022-11-29 16:46:42 base_stability_analyzer.py INFO    : Start testing of classifier 49 / 200\n",
      "2022-11-29 16:46:53 base_stability_analyzer.py INFO    : Classifier 49 / 200 was tested\n",
      "2022-11-29 16:46:53 base_stability_analyzer.py INFO    : Start testing of classifier 50 / 200\n",
      "2022-11-29 16:47:03 base_stability_analyzer.py INFO    : Classifier 50 / 200 was tested\n",
      "2022-11-29 16:47:03 base_stability_analyzer.py INFO    : Start testing of classifier 51 / 200\n",
      "2022-11-29 16:47:14 base_stability_analyzer.py INFO    : Classifier 51 / 200 was tested\n",
      "2022-11-29 16:47:14 base_stability_analyzer.py INFO    : Start testing of classifier 52 / 200\n",
      "2022-11-29 16:47:25 base_stability_analyzer.py INFO    : Classifier 52 / 200 was tested\n",
      "2022-11-29 16:47:25 base_stability_analyzer.py INFO    : Start testing of classifier 53 / 200\n",
      "2022-11-29 16:47:36 base_stability_analyzer.py INFO    : Classifier 53 / 200 was tested\n",
      "2022-11-29 16:47:36 base_stability_analyzer.py INFO    : Start testing of classifier 54 / 200\n"
     ]
    }
   ],
   "source": [
    "stability_fairness_analyzer.measure_metrics(make_plots=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}